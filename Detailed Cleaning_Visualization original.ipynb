{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "43de0fd2-4d3f-c80e-4f35-e3a89ce9d71f"
   },
   "source": [
    "# Detailed Data Cleaning/Visualization\n",
    "\n",
    "*A blog post about the final end-to-end solution (21st place) is available [here](http://alanpryorjr.com), and the source code is [on my github](https://github.com/apryor6/Kaggle-Competition-Santander)*\n",
    "\n",
    "*This is a Python version of a kernel I wrote in R for this dataset found [here](https://www.kaggle.com/apryor6/santander-product-recommendation/detailed-cleaning-visualization). There are some slight differences between how missing values are treated in Python and R, so the two kernels are not exactly the same, but I have tried to make them as similar as possible. This was done as a convenience to anybody who wanted to use my cleaned data as a starting point but prefers Python to R. It also is educational to compare how the same task can be accomplished in either language.*\n",
    "\n",
    "The goal of this competition is to predict which new Santander products, if any, a customer will purchase in the following month. Here, I will do some data cleaning, adjust some features, and do some visualization to get a sense of what features might be important predictors. I won't be building a predictive model in this kernel, but I hope this gives you some insight/ideas and gets you excited to build your own model.\n",
    "\n",
    "Let's get to it\n",
    "\n",
    "## First Glance\n",
    "Limit the number of rows read in to avoid memory crashes with the kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "85ebf22f-2673-cf92-99f2-f0024d3d7983"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\n\nIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\n\nImporting the numpy C-extensions failed. This error can happen for\nmany reasons, often due to issues with your setup or how NumPy was\ninstalled.\n\nWe have compiled some common reasons and troubleshooting tips at:\n\n    https://numpy.org/devdocs/user/troubleshooting-importerror.html\n\nPlease note and check the following:\n\n  * The Python version is: Python3.8 from \"D:\\Anaconda\\envs\\santander\\python.exe\"\n  * The NumPy version is: \"1.18.5\"\n\nand make sure that they are the versions you expect.\nPlease carefully study the documentation linked above for further help.\n\nOriginal error was: DLL load failed while importing _multiarray_umath: Le module spécifié est introuvable.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mD:\\Anaconda\\envs\\santander\\lib\\site-packages\\numpy\\core\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmultiarray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\santander\\lib\\site-packages\\numpy\\core\\multiarray.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moverrides\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_multiarray_umath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\santander\\lib\\site-packages\\numpy\\core\\overrides.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m from numpy.core._multiarray_umath import (\n\u001b[0m\u001b[0;32m      8\u001b[0m     add_docstring, implement_array_function, _get_implementing_args)\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _multiarray_umath: Le module spécifié est introuvable.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-6aa7f75dfa33>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pylab'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\santander\\lib\\site-packages\\numpy\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_distributor_init\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    143\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\santander\\lib\\site-packages\\numpy\\core\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     48\u001b[0m \"\"\" % (sys.version_info[0], sys.version_info[1], sys.executable,\n\u001b[0;32m     49\u001b[0m         __version__, exc)\n\u001b[1;32m---> 50\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0menvkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menv_added\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: \n\nIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\n\nImporting the numpy C-extensions failed. This error can happen for\nmany reasons, often due to issues with your setup or how NumPy was\ninstalled.\n\nWe have compiled some common reasons and troubleshooting tips at:\n\n    https://numpy.org/devdocs/user/troubleshooting-importerror.html\n\nPlease note and check the following:\n\n  * The Python version is: Python3.8 from \"D:\\Anaconda\\envs\\santander\\python.exe\"\n  * The NumPy version is: \"1.18.5\"\n\nand make sure that they are the versions you expect.\nPlease carefully study the documentation linked above for further help.\n\nOriginal error was: DLL load failed while importing _multiarray_umath: Le module spécifié est introuvable.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a833c896-c0a7-86b1-dff7-cdf3325cebfb"
   },
   "outputs": [],
   "source": [
    "limit_rows   = 15000000\n",
    "df           = pd.read_csv(\"train_filtered.csv\",dtype={\"sexo\":str,\n",
    "                                                    \"ind_nuevo\":str,\n",
    "                                                    \"ult_fec_cli_1t\":str,\n",
    "                                                    \"indext\":str}, nrows=limit_rows)\n",
    "unique_ids   = pd.Series(df[\"ncodpers\"].unique())\n",
    "# limit_people = 10000000\n",
    "# unique_id    = unique_ids.sample(n=limit_people)\n",
    "# df           = df[df.ncodpers.isin(unique_id)]\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8d1a3836-0310-6a6f-94fc-2a9c2a4984cc"
   },
   "source": [
    "We have a number of demographics for each individual as well as the products they currently own. To make a test set, I will separate the last month from this training data, and create a feature that indicates whether or not a product was newly purchased. First convert the dates. There's `fecha_dato`, the row-identifier date, and `fecha_alta`, the date that the customer joined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9dfc376a-b836-94b4-03e3-bc3740b97aa8"
   },
   "outputs": [],
   "source": [
    "df[\"fecha_dato\"] = pd.to_datetime(df[\"fecha_dato\"],format=\"%Y-%m-%d\")\n",
    "df[\"fecha_alta\"] = pd.to_datetime(df[\"fecha_alta\"],format=\"%Y-%m-%d\")\n",
    "df[\"fecha_dato\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5e439040-c7d7-1b7f-2954-ffb535d2bf64"
   },
   "source": [
    "I printed the values just to double check the dates were in standard Year-Month-Day format. I expect that customers will be more likely to buy products at certain months of the year (Christmas bonuses?), so let's add a month column. I don't think the month that they joined matters, so just do it for one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b5e8429d-a0f3-b5a5-81d6-7e524b0a660c"
   },
   "outputs": [],
   "source": [
    "df[\"month\"] = pd.DatetimeIndex(df[\"fecha_dato\"]).month\n",
    "df[\"age\"]   = pd.to_numeric(df[\"age\"], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "bdb7e954-d855-fd00-613e-1452067a8c99"
   },
   "source": [
    "Are there any columns missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7c2e1189-ac6b-d1bb-48a4-472c1328485d"
   },
   "outputs": [],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "87f2316f-9b93-13c8-7f22-a11eda6c7622"
   },
   "source": [
    "Definitely. Onto data cleaning.\n",
    "\n",
    "## Data Cleaning\n",
    "\n",
    "Going down the list, start with `age`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d0484da4-b8f3-a514-c441-eef972179098"
   },
   "outputs": [],
   "source": [
    "with sns.plotting_context(\"notebook\",font_scale=1.5):\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.distplot(df[\"age\"].dropna(),\n",
    "                 bins=80,\n",
    "                 kde=False,\n",
    "                 color=\"tomato\")\n",
    "    plt.title(\"Age Distribution\")\n",
    "    plt.ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c7e2eaae-4bef-d74f-ff3f-50322caf8bd3"
   },
   "source": [
    "In addition to NA, there are people with very small and very high ages.\n",
    "It's also interesting that the distribution is bimodal. There are a large number of university aged students, and then another peak around middle-age. Let's separate the distribution and move the outliers to the mean of the closest one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "73e3143f-d51b-bd0a-a8cc-64178de70e4e"
   },
   "outputs": [],
   "source": [
    "df.loc[df.age < 18,\"age\"]  = df.loc[(df.age >= 18) & (df.age <= 30),\"age\"].mean(skipna=True)\n",
    "df.loc[df.age > 100,\"age\"] = df.loc[(df.age >= 30) & (df.age <= 100),\"age\"].mean(skipna=True)\n",
    "df[\"age\"].fillna(df[\"age\"].mean(),inplace=True)\n",
    "df[\"age\"]                  = df[\"age\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1d867605-f48a-7109-afa0-de92b2d8fbdd"
   },
   "outputs": [],
   "source": [
    "with sns.plotting_context(\"notebook\",font_scale=1.5):\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.distplot(df[\"age\"].dropna(),\n",
    "                 bins=80,\n",
    "                 kde=False,\n",
    "                 color=\"tomato\")\n",
    "    plt.title(\"Age Distribution\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.xlim((15,100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6028f2ab-b7d5-920d-a313-e00776856f79"
   },
   "source": [
    "Looks better.  \n",
    "\n",
    "Next `ind_nuevo`, which indicates whether a customer is new or not. How many missing values are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "72710055-5dec-fafc-c712-27475eeb965b"
   },
   "outputs": [],
   "source": [
    "df[\"ind_nuevo\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a15606ec-bf21-afd6-d5cc-20b7ac0ebc42"
   },
   "source": [
    "Let's see if we can fill in missing values by looking how many months of history these customers have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e72879e7-8853-57da-5211-0bc07dc9baed"
   },
   "outputs": [],
   "source": [
    "months_active = df.loc[df[\"ind_nuevo\"].isnull(),:].groupby(\"ncodpers\", sort=False).size()\n",
    "months_active.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2e52e713-8002-1ddc-feff-2785f7a97578"
   },
   "source": [
    "Looks like these are all new customers, so replace accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "672d6595-2ddc-3a34-48d8-c6f98fe3e0ef"
   },
   "outputs": [],
   "source": [
    "df.loc[df[\"ind_nuevo\"].isnull(),\"ind_nuevo\"] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "07890c58-9e34-4d1a-e6b7-b63b3ab12943"
   },
   "source": [
    "Now, `antiguedad`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f5597d19-ba99-e4d6-36f7-8463b8199ff6"
   },
   "outputs": [],
   "source": [
    "df.antiguedad = pd.to_numeric(df.antiguedad,errors=\"coerce\")\n",
    "np.sum(df[\"antiguedad\"].isnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "78e8d734-464b-9ecf-3314-9cd0a8f1f28e"
   },
   "source": [
    "That number again. Probably the same people that we just determined were new customers. Double check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "88314fe6-4eff-7d0b-8d43-e2c1ae315965"
   },
   "outputs": [],
   "source": [
    "df.loc[df[\"antiguedad\"].isnull(),\"ind_nuevo\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5f923230-78ca-a90b-09fa-650cbee30890"
   },
   "source": [
    "Yup, same people. Let's give them minimum seniority."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "561ac875-a3c8-e843-caf7-aeafbc977185"
   },
   "outputs": [],
   "source": [
    "df.loc[df.antiguedad.isnull(),\"antiguedad\"] = df.antiguedad.min()\n",
    "df.loc[df.antiguedad <0, \"antiguedad\"]      = 0 # Thanks @StephenSmith for bug-find"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "00eec8e6-c8c7-5d32-aa7d-43e536368bb1"
   },
   "source": [
    "Some entries don't have the date they joined the company. Just give them something in the middle of the pack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "55f39399-dbb7-3b13-5393-f6ad89d4fe24"
   },
   "outputs": [],
   "source": [
    "dates=df.loc[:,\"fecha_alta\"].sort_values().reset_index()\n",
    "median_date = int(np.median(dates.index.values))\n",
    "df.loc[df.fecha_alta.isnull(),\"fecha_alta\"] = dates.loc[median_date,\"fecha_alta\"]\n",
    "df[\"fecha_alta\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "bae7c9c5-a972-c397-4c1d-be0d06f7066e"
   },
   "source": [
    "Next is `indrel`, which indicates:\n",
    "\n",
    "> 1 (First/Primary), 99 (Primary customer during the month but not at the end of the month)\n",
    "\n",
    "This sounds like a promising feature. I'm not sure if primary status is something the customer chooses or the company assigns, but either way it seems intuitive that customers who are dropping down are likely to have different purchasing behaviors than others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9286511c-1f0d-5c7a-e762-6bad69180144"
   },
   "outputs": [],
   "source": [
    "pd.Series([i for i in df.indrel]).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1f57156d-a8fa-6470-83b5-38b1684ca409"
   },
   "source": [
    "Fill in missing with the more common status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4bd3465b-5eae-2743-5929-f5779909df2d"
   },
   "outputs": [],
   "source": [
    "df.loc[df.indrel.isnull(),\"indrel\"] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "bf47c303-22a0-36b2-cd69-4598f6210e84"
   },
   "source": [
    "> tipodom\t- Addres type. 1, primary address\n",
    " cod_prov\t- Province code (customer's address)\n",
    "\n",
    "`tipodom` doesn't seem to be useful, and the province code is not needed because the name of the province exists in `nomprov`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "bfbcd9e1-6e22-d742-9daf-d05a471f056a"
   },
   "outputs": [],
   "source": [
    "df.drop([\"tipodom\",\"cod_prov\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b8f66021-233e-eb7b-10db-58a059df9306"
   },
   "source": [
    "Quick check back to see how we are doing on missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "96fc171a-6e3f-f6f9-93d0-c9f9e707d60b"
   },
   "outputs": [],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d85d2c58-b6cd-1928-a321-23467561c7d5"
   },
   "source": [
    "Getting closer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "cc0707d4-cea8-174f-16b7-f8fd3f8b67b5"
   },
   "outputs": [],
   "source": [
    "np.sum(df[\"ind_actividad_cliente\"].isnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "bd3325ce-c4c9-3c01-c8c1-900093f05bbf"
   },
   "source": [
    "By now you've probably noticed that this number keeps popping up. A handful of the entries are just bad, and should probably just be excluded from the model. But for now I will just clean/keep them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "afa661ef-5c01-ef33-3ac0-a7b35ecf2e27"
   },
   "outputs": [],
   "source": [
    "df.loc[df.ind_actividad_cliente.isnull(),\"ind_actividad_cliente\"] = \\\n",
    "df[\"ind_actividad_cliente\"].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b0400709-8b1d-1440-b940-d27ab17c528b"
   },
   "outputs": [],
   "source": [
    "df.nomprov.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "568e9011-a39a-ff51-67d5-3a260588f636"
   },
   "source": [
    "There was an issue with the unicode character ñ in [A Coruña](https://en.wikipedia.org/wiki/A_Coruña). I'll manually fix it, but if anybody knows a better way to catch cases like this I would be very glad to hear it in the comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0dbadbd2-76be-0789-f745-803f93585318"
   },
   "outputs": [],
   "source": [
    "df.loc[df.nomprov==\"CORU\\xc3\\x91A, A\",\"nomprov\"] = \"CORUNA, A\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ca29776f-143b-d2e0-ef05-3e573e5af04b"
   },
   "source": [
    "There's some rows missing a city that I'll relabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f2b0b646-b74a-8f51-d754-40e4c58c9578"
   },
   "outputs": [],
   "source": [
    "df.loc[df.nomprov.isnull(),\"nomprov\"] = \"UNKNOWN\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7acb976b-5e9a-51a6-dec2-422ef0b8d97d"
   },
   "source": [
    "Now for gross income, aka `renta`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9830d62e-2fd0-ae57-a616-2a58ef7c93e7"
   },
   "outputs": [],
   "source": [
    "df.renta.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7f3938b5-695f-2bc6-0145-37c81ef75be4"
   },
   "source": [
    "Here is a feature that is missing a lot of values. Rather than just filling them in with a median, it's probably more accurate to break it down region by region. To that end, let's take a look at the median income by region, and in the spirit of the competition let's color it like the Spanish flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.renta.isnull(),:].groupby(\"nomprov\").renta = df.loc[df.renta.notnull(),:].groupby(\"nomprov\").mean().renta\n",
    "df[\"MedianIncome\"] = df.loc[df.renta.notnull(),:].groupby(\"nomprov\").renta.transform(\"mean\")\n",
    "incomes = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "587bca44-b0ba-37a9-9b99-b715c690688d"
   },
   "outputs": [],
   "source": [
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "#df.loc[df.renta.notnull(),:].groupby(\"nomprov\").agg([{\"Sum\":sum},{\"Mean\":mean}])\n",
    "# incomes = df.loc[df.renta.notnull(),:].groupby(\"nomprov\").agg({\"renta\":{\"MedianIncome\":median}})\n",
    "incomes.sort_values([\"MedianIncome\"],inplace=True)\n",
    "incomes.reset_index(inplace=True)\n",
    "incomes.nomprov = incomes.nomprov.astype(\"category\", CategoricalDtype([i for i in df.nomprov.unique()], ordered=True))\n",
    "incomes.head()\n",
    "incomes = incomes[[\"MedianIncome\",\"nomprov\"]]\n",
    "df[\"MedianIncome\"] = df.loc[df.renta.notnull(),:].groupby(\"nomprov\").renta.transform(\"mean\")\n",
    "# medianIncome = df.groupby(\"nomprov\")[[\"MedianIncome\"]].reset_index()\n",
    "# incomes = df.loc[df.renta.notnull(),:].groupby(\"nomprov\").agg({\"renta\":{\"MedianIncome\":median}})\n",
    "# incomes.sort_values(by=(\"renta\",\"MedianIncome\"),inplace=True)\n",
    "# incomes.reset_index(inplace=True)\n",
    "# incomes.nomprov = incomes.nomprov.astype(\"category\", categories=[i for i in df.nomprov.unique()],ordered=False)\n",
    "# incomes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incomes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "fd49def1-8da1-2d6f-15b8-73eb2c44a237"
   },
   "outputs": [],
   "source": [
    "# with sns.axes_style({\n",
    "#         \"axes.facecolor\":   \"#ffc400\",\n",
    "#         \"axes.grid\"     :    False,\n",
    "#         \"figure.facecolor\": \"#c60b1e\"}):\n",
    "#     h = sns.factorplot(data=incomes,\n",
    "#                    x=\"nomprov\",\n",
    "#                    y=\"renta\",\n",
    "#                       hue=\"MedianIncome\",\n",
    "# #                    order=(i for i in incomes.nomprov),\n",
    "#                    size=6,\n",
    "#                    aspect=1.5,\n",
    "#                    scale=1.0,\n",
    "#                    color=\"#c60b1e\",\n",
    "#                    linestyles=\"None\")\n",
    "# plt.xticks(rotation=90)\n",
    "# plt.tick_params(labelsize=16,labelcolor=\"#ffc400\")#\n",
    "# plt.ylabel(\"Median Income\",size=32,color=\"#ffc400\")\n",
    "# plt.xlabel(\"City\",size=32,color=\"#ffc400\")\n",
    "# plt.title(\"Income Distribution by City\",size=40,color=\"#ffc400\")\n",
    "# plt.ylim(0,180000)\n",
    "# plt.yticks(range(0,180000,40000))\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.relplot(data=incomes,x='nomprov',y='MedianIncome', aspect=2)\n",
    "plt.xticks(rotation=90)\n",
    "plt.tick_params(labelsize=12)#\n",
    "plt.ylabel(\"Median Income\",size=20)\n",
    "plt.xlabel(\"City\",size=20)\n",
    "plt.title(\"Income Distribution by City\",size=30)\n",
    "plt.ylim(0,180000)\n",
    "plt.yticks(range(0,180000,40000))\n",
    "plt.grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6edf053e-2c31-3f39-e870-62d0b4cd30ac"
   },
   "source": [
    "There's a lot of variation, so I think assigning missing incomes by providence is a good idea. First group the data by city, and reduce to get the median. This intermediate data frame is joined by the original city names to expand the aggregated median incomes, ordered so that there is a 1-to-1 mapping between the rows, and finally the missing values are replaced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6fbf3979-141d-b716-3ba7-830d4b845172"
   },
   "outputs": [],
   "source": [
    "grouped        = df.groupby(\"nomprov\").agg({\"renta\":lambda x: x.median(skipna=True)}).reset_index()\n",
    "new_incomes    = pd.merge(df,grouped,how=\"inner\",on=\"nomprov\").loc[:, [\"nomprov\",\"renta_y\"]]\n",
    "new_incomes    = new_incomes.rename(columns={\"renta_y\":\"renta\"}).sort_values(\"renta\").sort_values(\"nomprov\")\n",
    "df.sort_values(\"nomprov\",inplace=True)\n",
    "df             = df.reset_index()\n",
    "new_incomes    = new_incomes.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "62958334-bca1-73e0-871e-20f70bed4867"
   },
   "outputs": [],
   "source": [
    "df.loc[df.renta.isnull(),\"renta\"] = new_incomes.loc[df.renta.isnull(),\"renta\"].reset_index()\n",
    "df.loc[df.renta.isnull(),\"renta\"] = df.loc[df.renta.notnull(),\"renta\"].median()\n",
    "df.sort_values(by=\"fecha_dato\",inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c5a83406-42f3-f518-224c-33cb63052cf6"
   },
   "source": [
    "The next columns with missing data I'll look at are features, which are just a boolean indicator as to whether or not that product was owned that month. Starting with `ind_nomina_ult1`.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4f280171-c0f3-c98e-bb35-ef903a9d9564"
   },
   "outputs": [],
   "source": [
    "df.ind_nomina_ult1.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "cb5e1ac0-7de1-412d-f35c-72f20e2e8e7f"
   },
   "source": [
    "I could try to fill in missing values for products by looking at previous months, but since it's such a small number of values for now I'll take the cheap way out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2ab8cd9b-5ec4-4c99-4f84-c394b39790d8"
   },
   "outputs": [],
   "source": [
    "df.loc[df.ind_nomina_ult1.isnull(), \"ind_nomina_ult1\"] = 0\n",
    "df.loc[df.ind_nom_pens_ult1.isnull(), \"ind_nom_pens_ult1\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3ad7235d-0368-a84e-6b29-ce4323590eb8"
   },
   "source": [
    "There's also a bunch of character columns that contain empty strings. In R, these are kept as empty strings instead of NA like in pandas. I originally worked through the data with missing values first in R, so if you are wondering why I skipped some NA columns here that's why. I'll take care of them now. For the most part, entries with NA will be converted to an unknown category.  \n",
    "First I'll get only the columns with missing values. Then print the unique values to determine what I should fill in with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "299fe28e-8844-ed3d-d558-30986db1ee60"
   },
   "outputs": [],
   "source": [
    "string_data = df.select_dtypes(include=[\"object\"])\n",
    "missing_columns = [col for col in string_data if string_data[col].isnull().any()]\n",
    "for col in missing_columns:\n",
    "    print(\"Unique values for {0}:\\n{1}\\n\".format(col,string_data[col].unique()))\n",
    "del string_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "17dd06a2-0c4e-49cd-21ef-2cc8235d1706"
   },
   "source": [
    "Okay, based on that and the definitions of each variable, I will fill the empty strings either with the most common value or create an unknown category based on what I think makes more sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c52777c3-06be-bf9f-0e33-3ae7e1b47d37"
   },
   "outputs": [],
   "source": [
    "df.loc[df.indfall.isnull(),\"indfall\"] = \"N\"\n",
    "df.loc[df.tiprel_1mes.isnull(),\"tiprel_1mes\"] = \"A\"\n",
    "df.tiprel_1mes = df.tiprel_1mes.astype(\"category\")\n",
    "\n",
    "# As suggested by @StephenSmith\n",
    "map_dict = { 1.0  : \"1\",\n",
    "            \"1.0\" : \"1\",\n",
    "            \"1\"   : \"1\",\n",
    "            \"3.0\" : \"3\",\n",
    "            \"P\"   : \"P\",\n",
    "            3.0   : \"3\",\n",
    "            2.0   : \"2\",\n",
    "            \"3\"   : \"3\",\n",
    "            \"2.0\" : \"2\",\n",
    "            \"4.0\" : \"4\",\n",
    "            \"4\"   : \"4\",\n",
    "            \"2\"   : \"2\"}\n",
    "\n",
    "df.indrel_1mes.fillna(\"P\",inplace=True)\n",
    "df.indrel_1mes = df.indrel_1mes.apply(lambda x: map_dict.get(x,x))\n",
    "df.indrel_1mes = df.indrel_1mes.astype(\"category\")\n",
    "\n",
    "\n",
    "unknown_cols = [col for col in missing_columns if col not in [\"indfall\",\"tiprel_1mes\",\"indrel_1mes\"]]\n",
    "for col in unknown_cols:\n",
    "    df.loc[df[col].isnull(),col] = \"UNKNOWN\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1434f0ea-f1f6-8f61-bbf8-6cf299339fc3"
   },
   "source": [
    "Let's check back to see if we missed anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "28ee02b3-7e9c-0a66-3541-211ccd9dc34f"
   },
   "outputs": [],
   "source": [
    "df[\"MedianIncome\"] = df.loc[df.renta.notnull(),:].groupby(\"nomprov\").renta.transform(\"mean\")\n",
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-35cb3c86e14d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train_ver2_complete.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.to_csv('train_ver2_complete.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import sqrtm\n",
    "def compute_svd(k,train_df):\n",
    "    U,s,V = np.linalg.svd(train_df,full_matrices=False)\n",
    "\n",
    "    s=np.diag(s)\n",
    "    \n",
    "    # Select k latent vector\n",
    "    s=s[0:k,0:k]\n",
    "    U=U[:,0:k]\n",
    "    V=V[0:k,:]\n",
    "\n",
    "    s_root=sqrtm(s)\n",
    "\n",
    "    Usk=np.dot(U,s_root)\n",
    "    skV=np.dot(s_root,V)\n",
    "    UsV = np.dot(Usk, skV)\n",
    "    return UsV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\santander\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3062: DtypeWarning: Columns (15) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"test_ver2.csv\",dtype={\"sexo\":str,\"ind_nuevo\":str,\"ult_fec_cli_1t\":str,\"indext\":str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  15889 1170544 1170545 ...  660240  660243  660248]\n",
      "929615\n"
     ]
    }
   ],
   "source": [
    "ncodpers_test = df_test.ncodpers.unique()\n",
    "print(ncodpers_test)\n",
    "# Create matrix for month 05-2016\n",
    "batch_1 = df[(df[\"fecha_dato\"]==\"2016-05-28\") & (df[\"ncodpers\"].isin(ncodpers_test))].copy()\n",
    "print(len(batch_1))\n",
    "ncodpers_batch_1 = batch_1.ncodpers.unique()\n",
    "# Create matrix for month 04-2016\n",
    "batch_2 = df[(df[\"fecha_dato\"]==\"2016-04-28\") & (df[\"ncodpers\"].isin(ncodpers_batch_1))].copy()\n",
    "ncodpers_batch_2 = batch_2.ncodpers.unique()\n",
    "# Remove users unpresent in month 04-2016\n",
    "# batch_1 = batch_1[batch_1[\"ncodpers\"].isin(ncodpers_batch_2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>fecha_dato</th>\n",
       "      <th>ncodpers</th>\n",
       "      <th>ind_empleado</th>\n",
       "      <th>pais_residencia</th>\n",
       "      <th>sexo</th>\n",
       "      <th>age</th>\n",
       "      <th>fecha_alta</th>\n",
       "      <th>ind_nuevo</th>\n",
       "      <th>antiguedad</th>\n",
       "      <th>...</th>\n",
       "      <th>ind_pres_fin_ult1</th>\n",
       "      <th>ind_reca_fin_ult1</th>\n",
       "      <th>ind_tjcr_fin_ult1</th>\n",
       "      <th>ind_valo_fin_ult1</th>\n",
       "      <th>ind_viv_fin_ult1</th>\n",
       "      <th>ind_nomina_ult1</th>\n",
       "      <th>ind_nom_pens_ult1</th>\n",
       "      <th>ind_recibo_ult1</th>\n",
       "      <th>month</th>\n",
       "      <th>MedianIncome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1596742</th>\n",
       "      <td>110658</td>\n",
       "      <td>2016-04-28</td>\n",
       "      <td>574631</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>H</td>\n",
       "      <td>43</td>\n",
       "      <td>2005-10-27</td>\n",
       "      <td>0</td>\n",
       "      <td>126</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>113738.117995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1673544</th>\n",
       "      <td>42686</td>\n",
       "      <td>2016-04-28</td>\n",
       "      <td>725997</td>\n",
       "      <td>N</td>\n",
       "      <td>FR</td>\n",
       "      <td>V</td>\n",
       "      <td>51</td>\n",
       "      <td>2007-10-16</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>99703.069946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596665</th>\n",
       "      <td>110488</td>\n",
       "      <td>2016-04-28</td>\n",
       "      <td>573146</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>V</td>\n",
       "      <td>74</td>\n",
       "      <td>2005-10-25</td>\n",
       "      <td>0</td>\n",
       "      <td>126</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>113738.117995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1611856</th>\n",
       "      <td>248151</td>\n",
       "      <td>2016-04-28</td>\n",
       "      <td>136173</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>V</td>\n",
       "      <td>50</td>\n",
       "      <td>1999-06-24</td>\n",
       "      <td>0</td>\n",
       "      <td>202</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>113738.117995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509016</th>\n",
       "      <td>666129</td>\n",
       "      <td>2016-04-28</td>\n",
       "      <td>1039102</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>H</td>\n",
       "      <td>48</td>\n",
       "      <td>2012-08-01</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>108449.110082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          index fecha_dato  ncodpers ind_empleado pais_residencia sexo  age  \\\n",
       "1596742  110658 2016-04-28    574631            N              ES    H   43   \n",
       "1673544   42686 2016-04-28    725997            N              FR    V   51   \n",
       "1596665  110488 2016-04-28    573146            N              ES    V   74   \n",
       "1611856  248151 2016-04-28    136173            N              ES    V   50   \n",
       "509016   666129 2016-04-28   1039102            N              ES    H   48   \n",
       "\n",
       "        fecha_alta ind_nuevo  antiguedad  ...  ind_pres_fin_ult1  \\\n",
       "1596742 2005-10-27         0         126  ...                  0   \n",
       "1673544 2007-10-16         0         102  ...                  0   \n",
       "1596665 2005-10-25         0         126  ...                  0   \n",
       "1611856 1999-06-24         0         202  ...                  0   \n",
       "509016  2012-08-01         0          44  ...                  0   \n",
       "\n",
       "        ind_reca_fin_ult1 ind_tjcr_fin_ult1 ind_valo_fin_ult1  \\\n",
       "1596742                 0                 0                 0   \n",
       "1673544                 0                 0                 0   \n",
       "1596665                 0                 0                 0   \n",
       "1611856                 0                 0                 0   \n",
       "509016                  0                 0                 0   \n",
       "\n",
       "        ind_viv_fin_ult1 ind_nomina_ult1 ind_nom_pens_ult1 ind_recibo_ult1  \\\n",
       "1596742                0               0                 0               0   \n",
       "1673544                0               0                 0               0   \n",
       "1596665                0               0                 0               0   \n",
       "1611856                0               0                 0               0   \n",
       "509016                 0               0                 0               0   \n",
       "\n",
       "        month   MedianIncome  \n",
       "1596742     4  113738.117995  \n",
       "1673544     4   99703.069946  \n",
       "1596665     4  113738.117995  \n",
       "1611856     4  113738.117995  \n",
       "509016      4  108449.110082  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_2.tail()# len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>fecha_dato</th>\n",
       "      <th>ncodpers</th>\n",
       "      <th>ind_empleado</th>\n",
       "      <th>pais_residencia</th>\n",
       "      <th>sexo</th>\n",
       "      <th>age</th>\n",
       "      <th>fecha_alta</th>\n",
       "      <th>ind_nuevo</th>\n",
       "      <th>antiguedad</th>\n",
       "      <th>...</th>\n",
       "      <th>ind_pres_fin_ult1</th>\n",
       "      <th>ind_reca_fin_ult1</th>\n",
       "      <th>ind_tjcr_fin_ult1</th>\n",
       "      <th>ind_valo_fin_ult1</th>\n",
       "      <th>ind_viv_fin_ult1</th>\n",
       "      <th>ind_nomina_ult1</th>\n",
       "      <th>ind_nom_pens_ult1</th>\n",
       "      <th>ind_recibo_ult1</th>\n",
       "      <th>month</th>\n",
       "      <th>MedianIncome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>762842</th>\n",
       "      <td>1492272</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>1329311</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>H</td>\n",
       "      <td>22</td>\n",
       "      <td>2014-10-09</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>166251.026441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762841</th>\n",
       "      <td>1492271</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>1329312</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>H</td>\n",
       "      <td>24</td>\n",
       "      <td>2014-10-09</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>166251.026441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762840</th>\n",
       "      <td>1492266</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>1329287</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>V</td>\n",
       "      <td>29</td>\n",
       "      <td>2014-10-09</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>166251.026441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762847</th>\n",
       "      <td>1492282</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>1329300</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>V</td>\n",
       "      <td>26</td>\n",
       "      <td>2014-10-09</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>166251.026441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929863</th>\n",
       "      <td>1323828</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>443155</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>V</td>\n",
       "      <td>27</td>\n",
       "      <td>2003-11-04</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>166251.026441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          index fecha_dato  ncodpers ind_empleado pais_residencia sexo  age  \\\n",
       "762842  1492272 2016-05-28   1329311            N              ES    H   22   \n",
       "762841  1492271 2016-05-28   1329312            N              ES    H   24   \n",
       "762840  1492266 2016-05-28   1329287            N              ES    V   29   \n",
       "762847  1492282 2016-05-28   1329300            N              ES    V   26   \n",
       "929863  1323828 2016-05-28    443155            N              ES    V   27   \n",
       "\n",
       "       fecha_alta ind_nuevo  antiguedad  ...  ind_pres_fin_ult1  \\\n",
       "762842 2014-10-09         0          19  ...                  0   \n",
       "762841 2014-10-09         0          19  ...                  0   \n",
       "762840 2014-10-09         0          19  ...                  0   \n",
       "762847 2014-10-09         0          19  ...                  0   \n",
       "929863 2003-11-04         0         150  ...                  0   \n",
       "\n",
       "       ind_reca_fin_ult1 ind_tjcr_fin_ult1 ind_valo_fin_ult1 ind_viv_fin_ult1  \\\n",
       "762842                 0                 0                 0                0   \n",
       "762841                 0                 0                 0                0   \n",
       "762840                 0                 0                 0                0   \n",
       "762847                 0                 0                 0                0   \n",
       "929863                 0                 0                 1                0   \n",
       "\n",
       "       ind_nomina_ult1 ind_nom_pens_ult1 ind_recibo_ult1 month   MedianIncome  \n",
       "762842               0                 0               0     5  166251.026441  \n",
       "762841               0                 0               0     5  166251.026441  \n",
       "762840               0                 0               0     5  166251.026441  \n",
       "762847               0                 0               0     5  166251.026441  \n",
       "929863               0                 0               0     5  166251.026441  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_1.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols =['ind_ahor_fin_ult1','ind_aval_fin_ult1','ind_cco_fin_ult1','ind_cder_fin_ult1','ind_cno_fin_ult1','ind_ctju_fin_ult1','ind_ctma_fin_ult1',\n",
    "       'ind_ctop_fin_ult1','ind_ctpp_fin_ult1','ind_deco_fin_ult1','ind_deme_fin_ult1','ind_dela_fin_ult1','ind_ecue_fin_ult1','ind_fond_fin_ult1',\n",
    "       'ind_hip_fin_ult1','ind_plan_fin_ult1','ind_pres_fin_ult1','ind_reca_fin_ult1','ind_tjcr_fin_ult1','ind_valo_fin_ult1','ind_viv_fin_ult1',\n",
    "       'ind_nomina_ult1','ind_nom_pens_ult1','ind_recibo_ult1']\n",
    "#Sort values by client id so that the matrices are coherent (for summation and prediction)\n",
    "batch_1_train = batch_1.sort_values('ncodpers')\n",
    "batch_2_train = batch_2.sort_values('ncodpers')\n",
    "\n",
    "ncodpers = batch_1_train.ncodpers\n",
    "\n",
    "x_1 = batch_1_train[cols]\n",
    "x_2 = batch_2_train[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ind_ahor_fin_ult1    int64\n",
       "ind_aval_fin_ult1    int64\n",
       "ind_cco_fin_ult1     int64\n",
       "ind_cder_fin_ult1    int64\n",
       "ind_cno_fin_ult1     int64\n",
       "ind_ctju_fin_ult1    int64\n",
       "ind_ctma_fin_ult1    int64\n",
       "ind_ctop_fin_ult1    int64\n",
       "ind_ctpp_fin_ult1    int64\n",
       "ind_deco_fin_ult1    int64\n",
       "ind_deme_fin_ult1    int64\n",
       "ind_dela_fin_ult1    int64\n",
       "ind_ecue_fin_ult1    int64\n",
       "ind_fond_fin_ult1    int64\n",
       "ind_hip_fin_ult1     int64\n",
       "ind_plan_fin_ult1    int64\n",
       "ind_pres_fin_ult1    int64\n",
       "ind_reca_fin_ult1    int64\n",
       "ind_tjcr_fin_ult1    int64\n",
       "ind_valo_fin_ult1    int64\n",
       "ind_viv_fin_ult1     int64\n",
       "ind_nomina_ult1      int64\n",
       "ind_nom_pens_ult1    int64\n",
       "ind_recibo_ult1      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1 = x_1.values\n",
    "x_2 = x_2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "929615"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruct = compute_svd(4,x_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.02255812e-04, 4.36753952e-05, 1.01561680e+00, 5.72912660e-04,\n",
       "       1.12724750e-01, 2.25051724e-05, 9.52717295e-03, 1.24774984e-01,\n",
       "       5.66775585e-02, 6.07922041e-04, 1.95474681e-03, 6.45425637e-02,\n",
       "       1.83623236e-01, 3.08885207e-02, 9.00839481e-03, 1.39326329e-02,\n",
       "       1.79778142e-03, 9.18359334e-02, 7.68683812e-02, 4.65422467e-02,\n",
       "       4.45879759e-03, 8.67834675e-02, 9.45462613e-02, 2.46027122e-01])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstruct[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def predict(UsV,threshold,k, init_df):\n",
    "    with open(\"test_results.csv\",'w') as results_file:\n",
    "        writer = csv.writer(results_file,delimiter=\",\")\n",
    "        writer.writerow(['ncodpers','added_products'])\n",
    "        for i, row in enumerate(tqdm(UsV)):\n",
    "            idxs = np.argsort(row)[-k:]\n",
    "            keys = [cols[k] for k in idxs]\n",
    "            final_values = [init_df.iloc[i][['ncodpers']].values[0]]\n",
    "            second_col = \" \"\n",
    "            for idx, key in enumerate(keys.copy()):\n",
    "                if row[idxs[idx]]>=threshold:\n",
    "                    second_col += key + \" \"\n",
    "            final_values.append(second_col)      \n",
    "            writer.writerow(final_values)\n",
    "                    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 929615/929615 [16:26<00:00, 942.77it/s]\n"
     ]
    }
   ],
   "source": [
    "predict(reconstruct_with_dico, 0.001, 7, batch_1_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import DictionaryLearning, MiniBatchDictionaryLearning \n",
    "from sklearn.preprocessing import StandardScaler, Normalizer, MinMaxScaler\n",
    "from time import time\n",
    "\n",
    "def dictionary_learning(data):\n",
    "    t0 = time()\n",
    "    dico = MiniBatchDictionaryLearning(n_components=20,alpha=0.7, n_iter=1000,transform_algorithm='lasso_lars')\n",
    "#     dico = DictionaryLearning(n_components=20, alpha=0.7,transform_algorithm='lasso_lars')\n",
    "    dico = dico.fit(data)\n",
    "    dt = time() - t0\n",
    "    print(\"done in {}\".format(dt))\n",
    "    return dico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\santander\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=3.320e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "D:\\Anaconda\\envs\\santander\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=3.320e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "D:\\Anaconda\\envs\\santander\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=3.320e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "D:\\Anaconda\\envs\\santander\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=3.320e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 10.172249555587769\n"
     ]
    }
   ],
   "source": [
    "dico = dictionary_learning(x_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "U = dico.transform(x_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(925252, 20)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#User vector\n",
    "U.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 24)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Products Vector : extracted components\n",
    "V = dico.components_\n",
    "V.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstructed matrix using a dictionary\n",
    "reconstruct_with_dico = U.dot(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00000000e+00,  0.00000000e+00,  3.19878028e-01,  0.00000000e+00,\n",
       "        1.38793533e-02,  0.00000000e+00,  5.28442004e-06,  4.51115419e-02,\n",
       "        3.16319811e-01,  1.83911022e-05,  1.68624972e-05,  2.73821884e-02,\n",
       "        1.20464411e-02,  1.37177068e-02,  8.17099004e-03,  2.66615340e-02,\n",
       "       -1.65659984e-05,  1.00812061e-02,  7.98834495e-03,  7.87095254e-03,\n",
       "       -3.61848525e-04, -8.19360882e-04, -1.24922343e-03,  1.25203367e-01])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstruct_with_dico[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternating Least Square for Implicit Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import implicit\n",
    "from scipy.sparse import coo_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train_ALS.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>657640</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>657640</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>657640</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>657640</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>657640</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0  1  2\n",
       "0  657640  0  0\n",
       "1  657640  1  0\n",
       "2  657640  2  0\n",
       "3  657640  3  0\n",
       "4  657640  4  0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\santander\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3062: DtypeWarning: Columns (15) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"test_ver2.csv\",dtype={\"sexo\":str,\"ind_nuevo\":str,\"ult_fec_cli_1t\":str,\"indext\":str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_user = coo_matrix((data[2],(data[1],data[0])))\n",
    "user_products = products_user.T.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = implicit.als.AlternatingLeastSquares(factors=4, regularization=0.01, iterations=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_val = 1\n",
    "data_conf =  (products_user*alpha_val).astype('double')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca51bbbdabbe403cbda5898286292192",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.fit(data_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.recommend(657650, user_products,filter_already_liked_items=False, N=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 657640,  657640,  657640, ..., 1550586, 1550586, 1550586],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products_user.col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, nan), (1, nan), (10, nan), (7, nan), (8, nan), (9, nan), (23, nan)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\santander\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3062: DtypeWarning: Columns (15) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"test_ver2.csv\",dtype={\"sexo\":str,\"ind_nuevo\":str,\"ult_fec_cli_1t\":str,\"indext\":str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  15889 1170544 1170545 ...  660240  660243  660248]\n",
      "929615\n"
     ]
    }
   ],
   "source": [
    "ncodpers_test = df_test.ncodpers.unique()\n",
    "print(ncodpers_test)\n",
    "# Create matrix for month 05-2016\n",
    "batch_1 = df[(df[\"fecha_dato\"]==\"2016-05-28\") & (df[\"ncodpers\"].isin(ncodpers_test))].copy()\n",
    "print(len(batch_1))\n",
    "ncodpers_batch_1 = batch_1.ncodpers.unique()\n",
    "# Create matrix for month 04-2016\n",
    "batch_2 = df[(df[\"fecha_dato\"]==\"2016-04-28\") & (df[\"ncodpers\"].isin(ncodpers_batch_1))].copy()\n",
    "ncodpers_batch_2 = batch_2.ncodpers.unique()\n",
    "# Remove users unpresent in month 04-2016\n",
    "batch_1 = batch_1[batch_1[\"ncodpers\"].isin(ncodpers_batch_2)]\n",
    "\n",
    "cols =['ind_ahor_fin_ult1','ind_aval_fin_ult1','ind_cco_fin_ult1','ind_cder_fin_ult1','ind_cno_fin_ult1','ind_ctju_fin_ult1','ind_ctma_fin_ult1',\n",
    "       'ind_ctop_fin_ult1','ind_ctpp_fin_ult1','ind_deco_fin_ult1','ind_deme_fin_ult1','ind_dela_fin_ult1','ind_ecue_fin_ult1','ind_fond_fin_ult1',\n",
    "       'ind_hip_fin_ult1','ind_plan_fin_ult1','ind_pres_fin_ult1','ind_reca_fin_ult1','ind_tjcr_fin_ult1','ind_valo_fin_ult1','ind_viv_fin_ult1',\n",
    "       'ind_nomina_ult1','ind_nom_pens_ult1','ind_recibo_ult1']\n",
    "#Sort values by client id so that the matrices are coherent (for summation and prediction)\n",
    "batch_1 = batch_1.sort_values('ncodpers')\n",
    "batch_2 = batch_2.sort_values('ncodpers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_cls = batch_2.copy()\n",
    "batch_cls[\"fidelity\"] =  batch_cls.fecha_dato - batch_cls.fecha_alta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ncodpers                    int64\n",
       "ind_empleado               object\n",
       "pais_residencia            object\n",
       "sexo                       object\n",
       "age                         int32\n",
       "ind_nuevo                  object\n",
       "antiguedad                  int64\n",
       "indrel                      int64\n",
       "indrel_1mes              category\n",
       "tiprel_1mes              category\n",
       "indresi                    object\n",
       "indext                     object\n",
       "canal_entrada              object\n",
       "indfall                    object\n",
       "ind_actividad_cliente     float64\n",
       "renta                     float64\n",
       "segmento                   object\n",
       "dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_cols = ['ind_empleado', 'sexo', 'ind_nuevo', 'indrel', 'indrel_1mes', 'tiprel_1mes', 'indresi', 'indext', 'conyuemp', 'indfall', 'tipodom', 'ind_actividad_cliente', 'segmento', 'pais_residencia', 'canal_entrada']\n",
    "batch_cls[cls_cols].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_cls[\"fidelity\"] = batch_cls[\"fidelity\"].dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ncodpers</th>\n",
       "      <th>ind_empleado</th>\n",
       "      <th>pais_residencia</th>\n",
       "      <th>sexo</th>\n",
       "      <th>age</th>\n",
       "      <th>ind_nuevo</th>\n",
       "      <th>antiguedad</th>\n",
       "      <th>indrel</th>\n",
       "      <th>indrel_1mes</th>\n",
       "      <th>tiprel_1mes</th>\n",
       "      <th>indresi</th>\n",
       "      <th>indext</th>\n",
       "      <th>canal_entrada</th>\n",
       "      <th>indfall</th>\n",
       "      <th>ind_actividad_cliente</th>\n",
       "      <th>renta</th>\n",
       "      <th>segmento</th>\n",
       "      <th>fidelity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1065163</th>\n",
       "      <td>15889</td>\n",
       "      <td>F</td>\n",
       "      <td>ES</td>\n",
       "      <td>V</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>254</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>S</td>\n",
       "      <td>N</td>\n",
       "      <td>KAT</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>326124.90</td>\n",
       "      <td>01 - TOP</td>\n",
       "      <td>7773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065162</th>\n",
       "      <td>15890</td>\n",
       "      <td>A</td>\n",
       "      <td>ES</td>\n",
       "      <td>V</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>255</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>S</td>\n",
       "      <td>N</td>\n",
       "      <td>KAT</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71461.20</td>\n",
       "      <td>01 - TOP</td>\n",
       "      <td>7773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065161</th>\n",
       "      <td>15892</td>\n",
       "      <td>F</td>\n",
       "      <td>ES</td>\n",
       "      <td>H</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>255</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>S</td>\n",
       "      <td>N</td>\n",
       "      <td>KAT</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>430477.41</td>\n",
       "      <td>01 - TOP</td>\n",
       "      <td>7773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064838</th>\n",
       "      <td>15893</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>V</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>255</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>S</td>\n",
       "      <td>N</td>\n",
       "      <td>KAT</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>430477.41</td>\n",
       "      <td>02 - PARTICULARES</td>\n",
       "      <td>6782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064837</th>\n",
       "      <td>15894</td>\n",
       "      <td>A</td>\n",
       "      <td>ES</td>\n",
       "      <td>V</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>255</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>S</td>\n",
       "      <td>N</td>\n",
       "      <td>KAT</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>281757.72</td>\n",
       "      <td>01 - TOP</td>\n",
       "      <td>7773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ncodpers ind_empleado pais_residencia sexo  age ind_nuevo  \\\n",
       "1065163     15889            F              ES    V   56         0   \n",
       "1065162     15890            A              ES    V   63         0   \n",
       "1065161     15892            F              ES    H   62         0   \n",
       "1064838     15893            N              ES    V   63         0   \n",
       "1064837     15894            A              ES    V   60         0   \n",
       "\n",
       "         antiguedad  indrel indrel_1mes tiprel_1mes indresi indext  \\\n",
       "1065163         254       1           1           A       S      N   \n",
       "1065162         255       1           1           A       S      N   \n",
       "1065161         255       1           1           A       S      N   \n",
       "1064838         255       1           1           A       S      N   \n",
       "1064837         255       1           1           A       S      N   \n",
       "\n",
       "        canal_entrada indfall  ind_actividad_cliente      renta  \\\n",
       "1065163           KAT       N                    1.0  326124.90   \n",
       "1065162           KAT       N                    1.0   71461.20   \n",
       "1065161           KAT       N                    1.0  430477.41   \n",
       "1064838           KAT       N                    1.0  430477.41   \n",
       "1064837           KAT       N                    1.0  281757.72   \n",
       "\n",
       "                  segmento  fidelity  \n",
       "1065163           01 - TOP      7773  \n",
       "1065162           01 - TOP      7773  \n",
       "1065161           01 - TOP      7773  \n",
       "1064838  02 - PARTICULARES      6782  \n",
       "1064837           01 - TOP      7773  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_cols.append(\"fidelity\")\n",
    "batch_cls[cls_cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ncodpers                    int64\n",
       "ind_empleado               object\n",
       "pais_residencia            object\n",
       "sexo                       object\n",
       "age                         int32\n",
       "ind_nuevo                  object\n",
       "antiguedad                  int64\n",
       "indrel                      int64\n",
       "ult_fec_cli_1t             object\n",
       "indrel_1mes              category\n",
       "tiprel_1mes              category\n",
       "indresi                    object\n",
       "indext                     object\n",
       "conyuemp                   object\n",
       "canal_entrada              object\n",
       "indfall                    object\n",
       "ind_actividad_cliente     float64\n",
       "renta                     float64\n",
       "segmento                   object\n",
       "fidelity                    int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_cls[cls_cols].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_category(df,col):\n",
    "    df = df.copy()\n",
    "    df[col] = df[col].astype(\"category\")\n",
    "    return df\n",
    "\n",
    "batch_cls = convert_to_category(batch_cls,\"ind_empleado\")\n",
    "batch_cls = convert_to_category(batch_cls,\"pais_residencia\")\n",
    "batch_cls = convert_to_category(batch_cls,\"sexo\")\n",
    "batch_cls = convert_to_category(batch_cls,\"ind_nuevo\")\n",
    "batch_cls = convert_to_category(batch_cls,\"indresi\")\n",
    "batch_cls = convert_to_category(batch_cls,\"indext\")\n",
    "batch_cls = convert_to_category(batch_cls,\"canal_entrada\")\n",
    "batch_cls = convert_to_category(batch_cls,\"indfall\")\n",
    "batch_cls = convert_to_category(batch_cls,\"segmento\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_category_to_num(df, col):\n",
    "    df = df.copy()\n",
    "    df[col] = df[col].cat.codes\n",
    "    return df\n",
    "\n",
    "batch_cls = convert_category_to_num(batch_cls,\"sexo\")\n",
    "batch_cls = convert_category_to_num(batch_cls,\"ind_empleado\")\n",
    "batch_cls = convert_category_to_num(batch_cls,\"pais_residencia\")\n",
    "batch_cls = convert_category_to_num(batch_cls,\"ind_nuevo\")\n",
    "batch_cls = convert_category_to_num(batch_cls,\"indresi\")\n",
    "batch_cls = convert_category_to_num(batch_cls,\"indext\")\n",
    "batch_cls = convert_category_to_num(batch_cls,\"canal_entrada\")\n",
    "batch_cls = convert_category_to_num(batch_cls,\"indfall\")\n",
    "batch_cls = convert_category_to_num(batch_cls,\"segmento\")\n",
    "batch_cls = convert_category_to_num(batch_cls,\"indrel_1mes\")\n",
    "batch_cls = convert_category_to_num(batch_cls,\"tiprel_1mes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ncodpers                   int64\n",
       "ind_empleado                int8\n",
       "pais_residencia             int8\n",
       "sexo                        int8\n",
       "age                        int32\n",
       "ind_nuevo                   int8\n",
       "antiguedad                 int64\n",
       "indrel                     int64\n",
       "indrel_1mes                 int8\n",
       "tiprel_1mes                 int8\n",
       "indresi                     int8\n",
       "indext                      int8\n",
       "canal_entrada              int16\n",
       "indfall                     int8\n",
       "ind_actividad_cliente    float64\n",
       "renta                    float64\n",
       "segmento                    int8\n",
       "fidelity                   int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_cls[cls_cols].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_cls = batch_1[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cls = batch_cls[cls_cols[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(X_cls)==len(Y_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert batch_cls.iloc[0]['ncodpers']==batch_1.iloc[0]['ncodpers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:   21.4s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:   35.8s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:   12.0s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:   26.1s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:   15.9s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:   34.9s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:   13.3s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:   29.1s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:   15.9s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:   34.5s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:   14.5s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:   31.4s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:   16.3s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:   35.2s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:   15.6s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:   34.7s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:   14.9s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:   32.1s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:   11.4s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:   24.9s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:   13.1s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:   29.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:   14.6s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:   32.7s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:   16.2s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:   37.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:   17.3s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:   37.8s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:   16.2s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:   34.9s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:   17.7s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:   38.7s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:   15.9s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:   34.3s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:   18.8s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:   40.8s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:   18.3s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:   40.2s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:   19.7s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:   41.2s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:   16.9s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:   37.5s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:   18.3s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:   40.1s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:   18.4s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:   39.7s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:   18.3s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:   39.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 855.6829426288605\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from time import time\n",
    "\n",
    "xtrain, xtest, ytrain, ytest=train_test_split(X_cls,Y_cls, train_size=0.8, random_state=0)\n",
    "# svc = SVC(gamma=\"scale\", verbose=True)\n",
    "# reg = LogisticRegression(random_state=0, verbose=1)\n",
    "clf = RandomForestClassifier(max_depth=5, random_state=0, n_jobs=2, verbose=1)\n",
    "t0 = time()\n",
    "model = MultiOutputClassifier(estimator=clf)\n",
    "model.fit(xtrain, ytrain)\n",
    "dt = time() - t0\n",
    "print(\"done in {}\".format(dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    2.5s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    2.5s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    3.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    2.7s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    2.8s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    2.7s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    2.8s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    2.8s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    2.9s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    2.7s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    3.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    3.1s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    3.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    2.8s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    2.8s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    2.8s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    2.7s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    3.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    3.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    2.8s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    2.8s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    2.8s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    2.8s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    2.9s finished\n",
      "D:\\Anaconda\\envs\\santander\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        64\n",
      "           1       1.00      0.08      0.15        12\n",
      "           2       0.74      0.85      0.79    447835\n",
      "           3       0.00      0.00      0.00       250\n",
      "           4       0.00      0.00      0.00     58486\n",
      "           5       0.95      0.11      0.20      5955\n",
      "           6       1.00      0.00      0.00      6336\n",
      "           7       0.00      0.00      0.00     80422\n",
      "           8       0.00      0.00      0.00     26486\n",
      "           9       0.00      0.00      0.00       256\n",
      "          10       0.00      0.00      0.00       802\n",
      "          11       0.00      0.00      0.00     25000\n",
      "          12       1.00      0.00      0.00     60690\n",
      "          13       0.00      0.00      0.00     11825\n",
      "          14       0.00      0.00      0.00      3604\n",
      "          15       0.00      0.00      0.00      5866\n",
      "          16       0.91      0.03      0.06      1576\n",
      "          17       0.00      0.00      0.00     36357\n",
      "          18       0.00      0.00      0.00     27887\n",
      "          19       0.00      0.00      0.00     17150\n",
      "          20       0.00      0.00      0.00      2384\n",
      "          21       0.00      0.00      0.00     38784\n",
      "          22       0.00      0.00      0.00     42391\n",
      "          23       0.78      0.00      0.01     90408\n",
      "\n",
      "   micro avg       0.74      0.39      0.51    990826\n",
      "   macro avg       0.27      0.05      0.05    990826\n",
      "weighted avg       0.48      0.39      0.36    990826\n",
      " samples avg       0.52      0.42      0.44    990826\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\santander\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anaconda\\envs\\santander\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "yhat = model.predict(xtrain)\n",
    "print(classification_report(ytrain,yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-16c9ec76e937>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'random_forest.sav'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "filename = 'random_forest.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from time import time\n",
    "import pickle\n",
    "loaded_model = pickle.load(open('random_forest.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"fecha_dato\"] = pd.to_datetime(df_test[\"fecha_dato\"],format=\"%Y-%m-%d\")\n",
    "df_test[\"fecha_alta\"] = pd.to_datetime(df_test[\"fecha_alta\"],format=\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fecha_dato               False\n",
       "ncodpers                 False\n",
       "ind_empleado             False\n",
       "pais_residencia          False\n",
       "sexo                      True\n",
       "age                      False\n",
       "fecha_alta               False\n",
       "ind_nuevo                False\n",
       "antiguedad               False\n",
       "indrel                   False\n",
       "ult_fec_cli_1t            True\n",
       "indrel_1mes               True\n",
       "tiprel_1mes               True\n",
       "indresi                  False\n",
       "indext                   False\n",
       "conyuemp                  True\n",
       "canal_entrada             True\n",
       "indfall                  False\n",
       "tipodom                  False\n",
       "cod_prov                  True\n",
       "nomprov                   True\n",
       "ind_actividad_cliente    False\n",
       "renta                    False\n",
       "segmento                  True\n",
       "fidelity                 False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['fidelity'] =  df_test.fecha_dato - df_test.fecha_alta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fecha_dato</th>\n",
       "      <th>ncodpers</th>\n",
       "      <th>ind_empleado</th>\n",
       "      <th>pais_residencia</th>\n",
       "      <th>sexo</th>\n",
       "      <th>age</th>\n",
       "      <th>fecha_alta</th>\n",
       "      <th>ind_nuevo</th>\n",
       "      <th>antiguedad</th>\n",
       "      <th>indrel</th>\n",
       "      <th>...</th>\n",
       "      <th>conyuemp</th>\n",
       "      <th>canal_entrada</th>\n",
       "      <th>indfall</th>\n",
       "      <th>tipodom</th>\n",
       "      <th>cod_prov</th>\n",
       "      <th>nomprov</th>\n",
       "      <th>ind_actividad_cliente</th>\n",
       "      <th>renta</th>\n",
       "      <th>segmento</th>\n",
       "      <th>fidelity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-06-28</td>\n",
       "      <td>15889</td>\n",
       "      <td>F</td>\n",
       "      <td>ES</td>\n",
       "      <td>V</td>\n",
       "      <td>56</td>\n",
       "      <td>1995-01-16</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>KAT</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>MADRID</td>\n",
       "      <td>1</td>\n",
       "      <td>326124.90</td>\n",
       "      <td>01 - TOP</td>\n",
       "      <td>7834 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-06-28</td>\n",
       "      <td>1170544</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>H</td>\n",
       "      <td>36</td>\n",
       "      <td>2013-08-28</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KAT</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>ALICANTE</td>\n",
       "      <td>0</td>\n",
       "      <td>NA</td>\n",
       "      <td>02 - PARTICULARES</td>\n",
       "      <td>1035 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-06-28</td>\n",
       "      <td>1170545</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>V</td>\n",
       "      <td>22</td>\n",
       "      <td>2013-08-28</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KHE</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>CORUÑA, A</td>\n",
       "      <td>1</td>\n",
       "      <td>NA</td>\n",
       "      <td>03 - UNIVERSITARIO</td>\n",
       "      <td>1035 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-06-28</td>\n",
       "      <td>1170547</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>H</td>\n",
       "      <td>22</td>\n",
       "      <td>2013-08-28</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KHE</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>BARCELONA</td>\n",
       "      <td>0</td>\n",
       "      <td>148402.98</td>\n",
       "      <td>03 - UNIVERSITARIO</td>\n",
       "      <td>1035 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-06-28</td>\n",
       "      <td>1170548</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>H</td>\n",
       "      <td>22</td>\n",
       "      <td>2013-08-28</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KHE</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>BALEARS, ILLES</td>\n",
       "      <td>0</td>\n",
       "      <td>106885.80</td>\n",
       "      <td>03 - UNIVERSITARIO</td>\n",
       "      <td>1035 days</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  fecha_dato  ncodpers ind_empleado pais_residencia sexo  age fecha_alta  \\\n",
       "0 2016-06-28     15889            F              ES    V   56 1995-01-16   \n",
       "1 2016-06-28   1170544            N              ES    H   36 2013-08-28   \n",
       "2 2016-06-28   1170545            N              ES    V   22 2013-08-28   \n",
       "3 2016-06-28   1170547            N              ES    H   22 2013-08-28   \n",
       "4 2016-06-28   1170548            N              ES    H   22 2013-08-28   \n",
       "\n",
       "  ind_nuevo  antiguedad  indrel  ... conyuemp  canal_entrada indfall tipodom  \\\n",
       "0         0         256       1  ...        N            KAT       N       1   \n",
       "1         0          34       1  ...      NaN            KAT       N       1   \n",
       "2         0          34       1  ...      NaN            KHE       N       1   \n",
       "3         0          34       1  ...      NaN            KHE       N       1   \n",
       "4         0          34       1  ...      NaN            KHE       N       1   \n",
       "\n",
       "  cod_prov         nomprov ind_actividad_cliente        renta  \\\n",
       "0     28.0          MADRID                     1    326124.90   \n",
       "1      3.0        ALICANTE                     0           NA   \n",
       "2     15.0       CORUÑA, A                     1           NA   \n",
       "3      8.0       BARCELONA                     0    148402.98   \n",
       "4      7.0  BALEARS, ILLES                     0    106885.80   \n",
       "\n",
       "             segmento  fidelity  \n",
       "0            01 - TOP 7834 days  \n",
       "1   02 - PARTICULARES 1035 days  \n",
       "2  03 - UNIVERSITARIO 1035 days  \n",
       "3  03 - UNIVERSITARIO 1035 days  \n",
       "4  03 - UNIVERSITARIO 1035 days  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "_cell_guid": "6fbf3979-141d-b716-3ba7-830d4b845172"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "could not convert string to float: '         NA'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mD:\\Anaconda\\envs\\santander\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36m_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minvalid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\santander\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36mf\u001b[1;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\santander\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36mnanmedian\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m    590\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_float_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"f8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    592\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '         NA'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-33dbf68bc475>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgrouped_test\u001b[0m        \u001b[1;33m=\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nomprov\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"renta\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mnew_incomes_test\u001b[0m    \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgrouped_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"inner\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"nomprov\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"nomprov\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"renta_y\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mnew_incomes_test\u001b[0m    \u001b[1;33m=\u001b[0m \u001b[0mnew_incomes_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"renta_y\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m\"renta\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"renta\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nomprov\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nomprov\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf_test\u001b[0m             \u001b[1;33m=\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\santander\\lib\\site-packages\\pandas\\core\\groupby\\generic.py\u001b[0m in \u001b[0;36maggregate\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    926\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_maybe_mangle_lambdas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    927\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 928\u001b[1;33m         \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_aggregate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    929\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhow\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    930\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\santander\\lib\\site-packages\\pandas\\core\\base.py\u001b[0m in \u001b[0;36m_aggregate\u001b[1;34m(self, arg, *args, **kwargs)\u001b[0m\n\u001b[0;32m    417\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 419\u001b[1;33m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_agg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_agg_1dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    420\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mSpecificationError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\santander\\lib\\site-packages\\pandas\\core\\base.py\u001b[0m in \u001b[0;36m_agg\u001b[1;34m(arg, func)\u001b[0m\n\u001b[0;32m    384\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0magg_how\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 386\u001b[1;33m                     \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0magg_how\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    387\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\santander\\lib\\site-packages\\pandas\\core\\base.py\u001b[0m in \u001b[0;36m_agg_1dim\u001b[1;34m(name, how, subset)\u001b[0m\n\u001b[0;32m    368\u001b[0m                         \u001b[1;34m\"nested dictionary is ambiguous in aggregation\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m                     )\n\u001b[1;32m--> 370\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mcolg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maggregate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0m_agg_2dim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\santander\\lib\\site-packages\\pandas\\core\\groupby\\generic.py\u001b[0m in \u001b[0;36maggregate\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_agg_general\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m                 \u001b[1;31m# TODO: KeyError is raised in _python_agg_general,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\santander\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36m_python_agg_general\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    934\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 936\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_apply_general\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    937\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    938\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filter_empty_groups\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\santander\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36m_python_apply_general\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    750\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    751\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_python_apply_general\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 752\u001b[1;33m         \u001b[0mkeys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmutated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_selected_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    753\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    754\u001b[0m         return self._wrap_applied_output(\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\santander\\lib\\site-packages\\pandas\\core\\groupby\\ops.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, f, data, axis)\u001b[0m\n\u001b[0;32m    204\u001b[0m             \u001b[1;31m# group might be modified\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m             \u001b[0mgroup_axes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_is_indexed_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_axes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m                 \u001b[0mmutated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\santander\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    912\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_python_agg_general\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    913\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_builtin_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 914\u001b[1;33m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    915\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m         \u001b[1;31m# iterate through \"columns\" ex exclusions to populate output dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-51-33dbf68bc475>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgrouped_test\u001b[0m        \u001b[1;33m=\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nomprov\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"renta\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mnew_incomes_test\u001b[0m    \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgrouped_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"inner\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"nomprov\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"nomprov\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"renta_y\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mnew_incomes_test\u001b[0m    \u001b[1;33m=\u001b[0m \u001b[0mnew_incomes_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"renta_y\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m\"renta\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"renta\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nomprov\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nomprov\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf_test\u001b[0m             \u001b[1;33m=\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\santander\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mstat_func\u001b[1;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11212\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlevel\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  11213\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_agg_by_level\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 11214\u001b[1;33m         return self._reduce(\n\u001b[0m\u001b[0;32m  11215\u001b[0m             \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  11216\u001b[0m         )\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\santander\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m   3889\u001b[0m                 )\n\u001b[0;32m   3890\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3891\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3892\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3893\u001b[0m         \u001b[1;31m# TODO(EA) dispatch to Index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\santander\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36m_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m                 \u001b[1;31m# object arrays that contain strings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: could not convert string to float: '         NA'"
     ]
    }
   ],
   "source": [
    "grouped_test        = df_test.groupby(\"nomprov\").agg({\"renta\":lambda x: x.median(skipna=True)}).reset_index()\n",
    "new_incomes_test    = pd.merge(df_test,grouped_test,how=\"inner\",on=\"nomprov\").loc[:, [\"nomprov\",\"renta_y\"]]\n",
    "new_incomes_test    = new_incomes_test.rename(columns={\"renta_y\":\"renta\"}).sort_values(\"renta\").sort_values(\"nomprov\")\n",
    "df_test.sort_values(\"nomprov\",inplace=True)\n",
    "df_test             = df_test.reset_index()\n",
    "new_incomes_test    = new_incomes_test.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_cell_guid": "62958334-bca1-73e0-871e-20f70bed4867"
   },
   "outputs": [],
   "source": [
    "df_test.loc[df_test.renta.isnull(),\"renta\"] = new_incomes_test.loc[df_test.renta.isnull(),\"renta\"].reset_index()\n",
    "df_test.loc[df_test.renta.isnull(),\"renta\"] = df_test.loc[df_test.renta.notnull(),\"renta\"].median()\n",
    "df_test.sort_values(by=\"fecha_dato\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "def train_svm(X, Y, colons):\n",
    "    svms = []\n",
    "    for k in tcolons:\n",
    "        clf = svm.SVC()\n",
    "        clf = clf.fit(X,Y[k])\n",
    "        svms.append(clf)\n",
    "    return svms\n",
    "\n",
    "train_svm(batch_cls[cls_cols[1:]], Y_cls, cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico = MiniBatchDictionaryLearning(n_components=20,alpha=0.7, n_iter=1000,transform_algorithm='lasso_lars')\n",
    "dico.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_reco = []\n",
    "for idx,item in enumerate(forUser10):\n",
    "    if(item>0.5):\n",
    "        valid_reco.append([cols[idx],item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_reco_list=[el[1] for el in valid_reco]\n",
    "valid_reco_columns=[el[0] for el in valid_reco]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(forUser10)\n",
    "# print(valid_reco_columns[])\n",
    "np.array(valid_reco_columns)[np.argsort(valid_reco_list)[::-1][:7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_2 = df[df[\"fecha_dato\"]==\"2016-05-28\"].copy()\n",
    "batch_2[df[\"ncodpers\"]==657790][cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_1.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".dot(Y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "51cfa3e9-cdb6-a949-ef3c-7f282ccda69b"
   },
   "source": [
    "Convert the feature columns into integer values (you'll see why in a second), and we're done cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2785dd85-e477-c2ca-b726-03fa317e32c2"
   },
   "outputs": [],
   "source": [
    "feature_cols = df.iloc[:1,].filter(regex=\"ind_+.*ult.*\").columns.values\n",
    "# for col in feature_cols:\n",
    "#     df[col] = df[col].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(feature_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "170d7959-9731-5fe4-b2ca-9fb4b81b3005"
   },
   "source": [
    "Now for the main event. To study trends in customers adding or removing services, I will create a label for each product and month that indicates whether a customer added, dropped or maintained that service in that billing cycle. I will do this by assigning a numeric id to each unique time stamp, and then matching each entry with the one from the previous month. The difference in the indicator value for each product then gives the desired value.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "684f824a-e5a5-abbc-4082-350b453e9a14"
   },
   "outputs": [],
   "source": [
    "unique_months = pd.DataFrame(pd.Series(df.fecha_dato.unique()).sort_values()).reset_index(drop=True)\n",
    "unique_months[\"month_id\"] = pd.Series(range(1,1+unique_months.size)) # start with month 1, not 0 to match what we already have\n",
    "unique_months[\"month_next_id\"] = 1 + unique_months[\"month_id\"]\n",
    "unique_months.rename(columns={0:\"fecha_dato\"},inplace=True)\n",
    "df = pd.merge(df,unique_months,on=\"fecha_dato\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1ee1e571-0483-a2f3-3804-5f2576bf4536"
   },
   "source": [
    "Now I'll build a function that will convert differences month to month into a meaningful label. Each month, a customer can either maintain their current status with a particular product, add it, or drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "659fc59d-dc8f-a4e6-eefd-a172b9577298"
   },
   "outputs": [],
   "source": [
    "def status_change(x):\n",
    "    diffs = x.diff().fillna(0)# first occurrence will be considered Maintained, \n",
    "    #which is a little lazy. A better way would be to check if \n",
    "    #the earliest date was the same as the earliest we have in the dataset\n",
    "    #and consider those separately. Entries with earliest dates later than that have \n",
    "    #joined and should be labeled as \"Added\"\n",
    "    label = [\"Added\" if i==1 \\\n",
    "         else \"Dropped\" if i==-1 \\\n",
    "         else \"Maintained\" for i in diffs]\n",
    "    return label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "88d69db7-acce-6278-923a-4da1f35f3a73"
   },
   "source": [
    "Now we can actually apply this function to each features using `groupby` followed by `transform` to broadcast the result back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "10f17b58-f5b6-bb7b-b822-c1c6db4d09e7"
   },
   "outputs": [],
   "source": [
    "# df.loc[:, feature_cols] = df..groupby(\"ncodpers\").apply(status_change)\n",
    "df.loc[:, feature_cols] = df.loc[:, [i for i in feature_cols]+[\"ncodpers\"]].groupby(\"ncodpers\").transform(status_change)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "21bba2fd-d0c4-8e1f-63de-0fe876f4e52e"
   },
   "source": [
    "I'm only interested in seeing what influences people adding or removing services, so I'll trim away any instances of \"Maintained\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6ec85399-7147-45fb-97ac-cd4b3f197e01"
   },
   "outputs": [],
   "source": [
    "df = pd.melt(df, id_vars   = [col for col in df.columns if col not in feature_cols],\n",
    "            value_vars= [col for col in feature_cols])\n",
    "df = df.loc[df.value!=\"Maintained\",:]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f81baa4c-7ae8-9977-d82f-31ec937bac2b"
   },
   "source": [
    "And we're done! I hope you found this useful, and if you want to checkout the rest of visualizations I made you can find them [here](https://www.kaggle.com/apryor6/santander-product-recommendation/detailed-cleaning-visualization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "722ba4e2-01e8-385e-bf23-662fd908d496"
   },
   "outputs": [],
   "source": [
    "# For thumbnail\n",
    "pylab.rcParams['figure.figsize'] = (6, 4)\n",
    "# with sns.axes_style({\n",
    "#         \"axes.facecolor\":   \"#ffc400\",\n",
    "#         \"axes.grid\"     :    False,\n",
    "#         \"figure.facecolor\": \"#c60b1e\"}):\n",
    "#     h = sns.factorplot(data=incomes,\n",
    "#                    x=\"nomprov\",\n",
    "#                    y=(\"renta\",\"MedianIncome\"),\n",
    "#                    order=(i for i in incomes.nomprov),\n",
    "#                    size=6,\n",
    "#                    aspect=1.5,\n",
    "#                    scale=0.75,\n",
    "#                    color=\"#c60b1e\",\n",
    "#                    linestyles=\"None\")\n",
    "# plt.xticks(rotation=90)\n",
    "# plt.tick_params(labelsize=12,labelcolor=\"#ffc400\")#\n",
    "# plt.ylabel(\"Median Income\",size=32,color=\"#ffc400\")\n",
    "# plt.xlabel(\"City\",size=32,color=\"#ffc400\")\n",
    "# plt.title(\"Income Distribution by City\",size=40,color=\"#ffc400\")\n",
    "# plt.ylim(0,180000)\n",
    "# plt.yticks(range(0,180000,40000))\n",
    "sns.relplot(data=incomes,x='nomprov',y='renta',hue='MedianIncome', aspect=2)\n",
    "plt.xticks(rotation=90)\n",
    "plt.tick_params(labelsize=14)#\n",
    "plt.ylabel(\"Median Income\",size=20)\n",
    "plt.xlabel(\"City\",size=20)\n",
    "plt.title(\"Income Distribution by City\",size=30)\n",
    "plt.ylim(0,180000)\n",
    "plt.yticks(range(0,180000,40000))\n",
    "plt.grid(False)"
   ]
  }
 ],
 "metadata": {
  "_change_revision": 0,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "santander",
   "language": "python",
   "name": "santander"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
